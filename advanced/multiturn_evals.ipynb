{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiturn Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll show how to create more advanced multiturn simulations with LangGraph, and subsequently evaluate the multiturn interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complicated evaluations require a more complex agent than our simple ELI5 workflow in the basics folder. We've defined a multiagent that acts as a customer service assistant for a fictional music store.\n",
    "\n",
    "This customer service assistant consists of a supervisor and two subagents: an invoice subagent and a music subagent. The invoice subagent handles billing related requests, while the music subagent handles music related requests. The supervisor handles routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent import multiagent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "from langsmith import Client # Set up LangSmith client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementation details, see the multiagent.py file. Tools accessible to our subagents are available in the multiagent_tools.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Multiple Turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the openevals package maintained by LangChain to simulate a user interaction with our multiagent. During our run function, we'll take in a starting question and a user description to seed the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a dataset with sample questions and expected output trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"simulated_user_prompt\": \"\"\"\n",
    "            You are a user browsing the music catalog of a digital music store.\n",
    "            You are a big fan of Queen, but are exploring some other genres. \n",
    "            After at maximum 2 other genres, you should ask for rock recommendations.\n",
    "            If any songs by Queen are returned, you should ask for songs by Queen.\n",
    "            \"\"\",\n",
    "            \"seed_messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"What opera songs do you have?\"},\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"trajectory\": [\n",
    "                {'role': 'user', 'content': 'What opera songs do you have?'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'We have one opera song:\\n\\n• \"Die Zauberflöte, K.620: \\'Der Hölle Rache Kocht in Meinem Herze\\'\"\\n\\nLet me know if you\\'d like additional details about this performance.'}, \n",
    "                {'role': 'user', 'content': 'Thanks for the opera suggestion! Could you also recommend some jazz songs?'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Here are some jazz songs available from our catalog:\\n\\n• \"OAM\\'s Blues\" – by Aaron Goldberg  \\n• \"Amanda\" – by Aisha Duo  \\n• \"Desafinado\" – by Antônio Carlos Jobim  \\n• \"Quadrant\" – by Billy Cobham  \\n• \"Roll Call\" – by Dennis Chambers  \\n• \"Jeepers Creepers\" – by Gene Krupa\\n\\nLet me know if you\\'d like additional details about any of these tunes!'}, \n",
    "                {'role': 'user', 'content': \"Thanks for the jazz options! Now I'd like some rock song recommendations, please.\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Here are some rock song recommendations from our catalog:\\n\\n• \"For Those About To Rock (We Salute You)\" – by AC/DC  \\n• \"Balls to the Wall\" – by Accept  \\n• \"All I Really Want\" – by Alanis Morissette  \\n• \"Money\" – by BackBeat  \\n• \"Susie Q\" – by Creedence Clearwater Revival\\n\\nLet me know if you\\'d like more details about any of these tracks!'},\n",
    "                {'role': 'user', 'content': 'Thanks for the rock recommendations! Do you have any songs by Queen available?'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': \"It looks like we don't have any songs by Queen in our catalog at the moment. Can I help you explore another artist or perhaps a different style?\"},\n",
    "                {'role': 'user', 'content': \"Since Queen songs aren't available, could you recommend some classic rock songs or bands similar to Queen?\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Here are some classic rock options from our catalog that carry a similar energy to Queen:\\n\\n• \"For Those About To Rock (We Salute You)\" – by AC/DC  \\n• \"Walk On Water\" – by Aerosmith  \\n• \"Susie Q\" – by Creedence Clearwater Revival\\n\\nThese selections offer a powerful rock vibe and captivating showmanship reminiscent of Queen\\'s style. Let me know if you\\'d like more information on any of these tracks!'}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"simulated_user_prompt\": \n",
    "            \"\"\"\n",
    "            You are a user who had a bad experience with a digital music store.\n",
    "            You should insult the customer service assistant once before continuing the conversation.\n",
    "            You want to know how much your most recent purchase was.\n",
    "            Your customer ID is 1, but you will not provide this information unless asked. \n",
    "            \"\"\",\n",
    "            \"seed_messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"You guys really suck.\"},\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"trajectory\": [\n",
    "                {'role': 'user', 'content': 'You guys really suck.'}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': \"I'm sorry to hear that you're upset. Your feedback is important to us, and I'd like to understand what went wrong so we can address your concerns. Could you please provide more details about the issue you're experiencing or what you'd like help with?\"}, \n",
    "                {'role': 'user', 'content': \"I want to know how much my most recent purchase was. Don't ask me for my customer ID unless you really need it.\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'I need your customer ID to locate and review your invoice details. Could you please provide your customer ID?'}, \n",
    "                {'role': 'user', 'content': 'Fine, my customer ID is 1. Now, can you tell me how much my last purchase was?'},\n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': 'Thank you for providing your customer ID. I’ve verified your account details, and your most recent purchase, made on 2025-08-07, was for $8.91. Is there anything else I can help you with today?'}, \n",
    "                {'role': 'user', 'content': \"Thanks for the info. That's all I needed for now.\"}, \n",
    "                {'role': 'assistant', 'name': 'supervisor', 'content': \"You're welcome! I'm glad I could help. If you have any more questions, please don't hesitate to reach out. Have a great day!\"}, \n",
    "                {'role': 'user', 'content': 'Yeah, whatever. Goodbye.'}, \n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_name = \"dbt-multiturn-evals\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs=[ex[\"inputs\"] for ex in examples],\n",
    "        outputs=[ex[\"outputs\"] for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a run function for our multiagent that is compatible with the openevals run_multiturn_simulation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.types import ChatCompletionMessage\n",
    "from multiagent import multiagent\n",
    "# Running simulation requires a func that takes in a chat message (dict with \"role\" and \"content\" keys) and a thread_id as a kwarg\n",
    "# This function should return a chat message as output with at least role and content keys (other keys optional)\n",
    "def run_multiagent(message: ChatCompletionMessage, *, thread_id: str, **kwargs):\n",
    "    res = multiagent.invoke(\n",
    "        {\"messages\": [message]}, \n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    return res[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define a run function for our evaluation, that can take in dataset inputs and use the examples to seed our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openevals.simulators import run_multiturn_simulation, create_llm_simulated_user\n",
    "\n",
    "\n",
    "def run_simulation(inputs: dict):\n",
    "    # Create a simulated user with seeded messages and system prompt from our dataset\n",
    "    user = create_llm_simulated_user(\n",
    "        system=inputs[\"simulated_user_prompt\"],\n",
    "        model=\"openai:gpt-4.1-mini\",\n",
    "        fixed_responses=inputs[\"seed_messages\"],\n",
    "    )\n",
    "\n",
    "    # Next, let's use openevals to run a simulation with our multiagent\n",
    "    simulator_result = run_multiturn_simulation(\n",
    "        app=run_multiagent,\n",
    "        user=user,\n",
    "        max_turns=5,\n",
    "    )\n",
    "\n",
    "    # Return the full conversation trajectory as an output\n",
    "    return {\"trajectory\": simulator_result[\"trajectory\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run our simulation function to see what the outputs look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What opera songs do you have?\n",
      "assistant: We currently have an opera piece in our catalog: \"Die Zauberflöte, K.620: 'Der Hölle Rache Kocht in Meinem Herze'\" performed by Sir Georg Solti, Sumi Jo, & the Wiener Philharmoniker. \n",
      "\n",
      "Would you like more details about this opera track, or would you like to explore additional opera selections?\n",
      "user: I'd like to explore some jazz music now. Could you recommend some jazz tracks?\n",
      "assistant: We've got a few exciting jazz tracks available for you! Here are some options from our catalog:\n",
      "\n",
      "• \"OAM's Blues\" by Aaron Goldberg  \n",
      "• \"Amanda\" by Aisha Duo  \n",
      "• \"Desafinado\" by Antônio Carlos Jobim  \n",
      "• \"Quadrant\" by Billy Cobham  \n",
      "• \"Roll Call\" by Dennis Chambers  \n",
      "• \"Jeepers Creepers\" by Gene Krupa  \n",
      "• \"Doce De Carnaval (Candy All)\" by Gilberto Gil  \n",
      "• \"Colibri\" by Incognito\n",
      "\n",
      "Would you like more details on any of these tracks, or would you like additional recommendations?\n",
      "user: Thanks for the jazz options! Now, could you recommend some rock songs?\n",
      "assistant: We've got some awesome rock tracks available! Here are the options again:\n",
      "\n",
      "• \"For Those About To Rock (We Salute You)\" by AC/DC  \n",
      "• \"Balls to the Wall\" by Accept  \n",
      "• \"Walk On Water\" by Aerosmith  \n",
      "• \"All I Really Want\" by Alanis Morissette  \n",
      "• \"We Die Young\" by Alice In Chains  \n",
      "• \"Cochise\" by Audioslave  \n",
      "• \"Money\" by BackBeat  \n",
      "• \"Susie Q\" by Creedence Clearwater Revival\n",
      "\n",
      "Would you like more details on any of these songs, or would you like to explore further recommendations?\n",
      "user: Could you tell me more about \"Walk On Water\" by Aerosmith? And after that, could you also show me some songs by Queen?\n",
      "assistant: Here are the details for \"Walk On Water\" by Aerosmith:\n",
      "\n",
      "• Album: Aerosmith Greatest Hits Vol. 1  \n",
      "• Release Year: 1994  \n",
      "• Duration: 5:02  \n",
      "• Genre: Rock\n",
      "\n",
      "And here are some Queen songs available in our catalog:\n",
      "\n",
      "• \"Bohemian Rhapsody\"  \n",
      "• \"Don't Stop Me Now\"  \n",
      "• \"Another One Bites The Dust\"  \n",
      "• \"We Will Rock You\"\n",
      "\n",
      "Please let me know if you need additional details for any of these or if you'd like further recommendations!\n",
      "user: I'd love to know more about \"Bohemian Rhapsody\" by Queen. Could you provide details on that track?\n",
      "assistant: Here are the details for \"Bohemian Rhapsody\" by Queen:\n",
      "\n",
      "• Album: A Night at the Opera  \n",
      "• Release Year: 1975  \n",
      "• Duration: Approximately 5:55  \n",
      "• Genre: Rock/Progressive Rock\n",
      "\n",
      "Additional Details:  \n",
      "\"Bohemian Rhapsody\" is one of Queen’s most iconic tracks. Its innovative structure fuses a ballad segment, an operatic passage, a hard rock section, and a reflective coda. Celebrated for its creative composition and unique style, the song has captured the hearts of listeners worldwide and remains a timeless classic.\n",
      "\n",
      "Would you like to explore more information or need further assistance?\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_trajectory(trajectory):\n",
    "    for message in trajectory:\n",
    "        print(f\"{message['role']}: {message['content']}\")\n",
    "\n",
    "results = run_simulation(examples[0][\"inputs\"])\n",
    "pretty_print_trajectory(results[\"trajectory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create an LLM as a Judge to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "\n",
    "model = ChatOpenAI(model=\"o3-mini\")\n",
    "\n",
    "judge_prompt = \"\"\"\n",
    "You are a helpful assistant that evaluates the quality of a customer service assistant's response to a customer's request.\n",
    "You will be given a conversation between a customer and a customer service assistant.\n",
    "\n",
    "High quality customer service assistant responses:\n",
    "- Are helpful and informative\n",
    "- Are concise and to the point\n",
    "- Are professional and respectful\n",
    "\n",
    "Low quality customer service assistant responses:\n",
    "- Are rude or dismissive\n",
    "- Ignore the customer's request without reasonable justification\n",
    "- Are not helpful or informative\n",
    "\n",
    "Provided is the conversation\n",
    "<conversation>\n",
    "{conversation}\n",
    "</conversation>\n",
    "\n",
    "Also provided is a reference conversation that represents a high quality customer service.\n",
    "<reference_conversation>\n",
    "{reference_conversation}\n",
    "</reference_conversation>\n",
    "\n",
    "Please evaluate the quality of the customer service assistant's responses based on the rubric provided.\n",
    "\"\"\"\n",
    "\n",
    "class Helpfulness(TypedDict):\n",
    "    \"\"\"Compare the reference conversation and actual conversation and measure the helpfulness of the customer service assistant.\"\"\"\n",
    "    reasoning: Annotated[str, ..., \"Explain your reasoning for whether the actual response is correct or not.\"]\n",
    "    helpful: Annotated[bool, ..., \"True if the customer service assistant is helpful, otherwise False.\"]\n",
    "\n",
    "\n",
    "def helpfulness(inputs: dict, outputs: dict, reference_outputs: dict):\n",
    "    conversation = outputs[\"trajectory\"]\n",
    "    reference_conversation = reference_outputs[\"trajectory\"]\n",
    "\n",
    "    judge_llm = model.with_structured_output(Helpfulness)\n",
    "    results = judge_llm.invoke(judge_prompt.format(conversation=conversation, reference_conversation=reference_conversation))\n",
    "    return results[\"helpful\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to run some evaluations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertxu/Desktop/Projects/customer/dbt/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'multiagent-multiturn-da549230' at:\n",
      "https://smith.langchain.com/o/bcad64b4-50f8-4e66-a0be-8dbaf6f6619c/datasets/e6a30512-3c05-4c38-89cc-843ad929cd67/compare?selectedSessions=3023a2dc-90fe-4f87-b5a1-7d66e3c063bc\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:34, 47.32s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"dbt-multiturn-evals\"\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    run_simulation,\n",
    "    data=dataset_name,\n",
    "    evaluators=[helpfulness],\n",
    "    experiment_prefix=\"multiagent-multiturn\",\n",
    "    num_repetitions=1,\n",
    "    max_concurrency=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
